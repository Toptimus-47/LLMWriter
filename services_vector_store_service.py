{"cells":[{"cell_type":"code","source":"# services/vector_store_service.py\nimport os\nimport faiss\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nfrom typing import List, Tuple\nfrom config import config\n\nclass VectorStoreService:\n    \"\"\"\n    Faiss를 사용한 벡터 검색을 담당하는 서비스.\n    각 인스턴스는 특정 소설의 디렉토리에 종속됩니다.\n    \"\"\"\n    def __init__(self, novel_dir: str):\n        self.novel_dir = novel_dir\n        self.vector_store_dir = os.path.join(self.novel_dir, config.VECTOR_STORE_DIR)\n        self.index_path = os.path.join(self.vector_store_dir, config.FAISS_INDEX_NAME)\n        \n        # 임베딩 모델은 한 번만 로드\n        if not hasattr(VectorStoreService, '_model'):\n             VectorStoreService._model = SentenceTransformer(config.EMBEDDING_MODEL)\n        self.model = VectorStoreService._model\n\n        self.index = None\n        self.documents = [] # (chapter_index, text) 튜플 저장\n        self._load_or_create_index()\n\n    def _load_or_create_index(self):\n        \"\"\"인덱스 파일이 있으면 로드하고, 없으면 새로 생성합니다.\"\"\"\n        if os.path.exists(self.index_path):\n            try:\n                self.index = faiss.read_index(self.index_path)\n                # 문서 데이터도 함께 로드해야 함 (간단하게 텍스트 파일로 저장)\n                doc_path = f\"{self.index_path}.docs.json\"\n                if os.path.exists(doc_path):\n                    with open(doc_path, 'r', encoding='utf-8') as f:\n                        self.documents = json.load(f)\n            except Exception as e:\n                print(f\"인덱스 로드 실패, 새로 생성합니다: {e}\")\n                self._create_new_index()\n        else:\n            self._create_new_index()\n\n    def _create_new_index(self):\n        \"\"\"새로운 Faiss 인덱스를 생성합니다.\"\"\"\n        os.makedirs(self.vector_store_dir, exist_ok=True)\n        embedding_dim = self.model.get_sentence_embedding_dimension()\n        self.index = faiss.IndexFlatL2(embedding_dim)\n        self.documents = []\n\n    def save_index(self):\n        \"\"\"현재 인덱스와 문서 목록을 파일에 저장합니다.\"\"\"\n        if self.index:\n            faiss.write_index(self.index, self.index_path)\n            doc_path = f\"{self.index_path}.docs.json\"\n            with open(doc_path, 'w', encoding='utf-8') as f:\n                json.dump(self.documents, f, ensure_ascii=False, indent=4)\n\n    def add_document(self, text: str, chapter_index: int):\n        \"\"\"문서를 인덱스에 추가합니다.\"\"\"\n        if not text: return\n        \n        embedding = self.model.encode([text], convert_to_tensor=False)\n        self.index.add(np.array(embedding, dtype=np.float32))\n        self.documents.append((chapter_index, text))\n\n    def search(self, query: str, k: int = 3) -> List[str]:\n        \"\"\"쿼리와 유사한 문서를 검색하여 텍스트 리스트를 반환합니다.\"\"\"\n        if not query or self.index.ntotal == 0:\n            return []\n\n        query_embedding = self.model.encode([query])\n        _, indices = self.index.search(np.array(query_embedding, dtype=np.float32), k)\n        \n        results = []\n        for i in indices[0]:\n            if 0 <= i < len(self.documents):\n                results.append(self.documents[i][1]) # (chapter_index, text)에서 text만 반환\n        return results","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}